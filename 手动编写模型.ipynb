{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXdFdLYgxGfX2jrriXA6bX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndsoi/ndsoi/blob/main/%E6%89%8B%E5%8A%A8%E7%BC%96%E5%86%99%E6%A8%A1%E5%9E%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手动实现向前传播、反向传播调参"
      ],
      "metadata": {
        "id": "4f_AahYqJu-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DCBsNIOZQTZd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们来实现一个简单的Python类NaiveDense，它创建了两个TensorFlow变量W和b，并定义了一个__call__()方法供外部调用，以实现上述变换。"
      ],
      "metadata": {
        "id": "c6ySQaVkJ90C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NavieDense:\n",
        "  def __init__(self,input_size,output_size,activation):\n",
        "    self.activation = activation\n",
        "    self.W = tf.Variable(tf.random.uniform((input_size,output_size),minval=0,maxval=1e-1))    # 为什么选用的是random.uniform，可以是zeros吗\n",
        "    self.b = tf.Variable(tf.zeros(output_size,))\n",
        "  def __call__(self,inputs):\n",
        "    return self.activation(tf.matmul(inputs,self.W)+self.b)\n",
        "\n",
        "  # 为什么会有下一行注释?\n",
        "  @property\n",
        "  def weights(self):\n",
        "    return [self.W,self.b]\n"
      ],
      "metadata": {
        "id": "_oMmhNCWJ4Q3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "简单的Sequential类\n",
        "下面我们创建一个NaiveSequential类，将这些层链接起来。它封装了一个层列表，并定义了一个__call__()方法供外部调用。这个方法将按顺序调用输入的层。它还有一个weights属性，用于记录该层的参数。"
      ],
      "metadata": {
        "id": "zJQC3eGdKORe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NavieSequential:\n",
        "  def __init__(self,layers):\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self,inputs):\n",
        "    re = inputs   #自己写的是 tf.Variable(tf.zeros((inputs.shape)))\n",
        "    for layer in self.layers:\n",
        "      re = layer(re)\n",
        "    return re\n",
        "\n",
        "  @property\n",
        "  def weights(self):\n",
        "    weights = []\n",
        "    for layer in self.layers:\n",
        "      weights += layer.weights\n",
        "    return weights\n",
        "\n"
      ],
      "metadata": {
        "id": "SW7OOOOwKP-B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用这个NaiveDense类和NaiveSequential类，我们可以创建一个与Keras类似的模型。"
      ],
      "metadata": {
        "id": "e9ucEeziKQOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = NavieSequential(input,[NavieDense(512,\"relu\"),NavieDense(10,\"softmax\")])\n",
        "\n",
        "model = NavieSequential([\n",
        "    NavieDense(input_size=28*28,output_size=512,activation=tf.nn.relu),NavieDense(input_size=512,output_size=10,activation=tf.nn.softmax)])\n"
      ],
      "metadata": {
        "id": "z1fy4dVhKVxn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "批量生成器\n",
        "接下来，我们需要对MNIST数据进行小批量迭代。这很简单。"
      ],
      "metadata": {
        "id": "GAEfxmzgKWB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchGenerator:\n",
        "  def __init__(self,image,label,batch_size=128):\n",
        "    self.image = image\n",
        "    self.label = label\n",
        "    self.batch_num = math.ceil(len(label)/batch_size)\n",
        "    self.curindex = 0\n",
        "\n",
        "  def next(self):\n",
        "    if self.curindex >= self.batch_num:\n",
        "      self.curindex = 0\n",
        "    st = self.curindex\n",
        "    ed = self.curindex+128\n",
        "    self.curindex+=128\n",
        "    return self.image[st:ed],self.label[st:ed]\n",
        "\n",
        "  def batch_num(self):\n",
        "    return self.batch_num\n"
      ],
      "metadata": {
        "id": "JQp-0dk-Kf4a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5.2　完成一次训练步骤\n",
        "最难的一步就是“训练步骤”，即在一批数据上运行模型后更新模型权重。我们需要做到以下几点。\n",
        "(1)计算模型对图像批量的预测值。\n",
        "(2)根据实际标签，计算这些预测值的损失值。\n",
        "(3)计算损失相对于模型权重的梯度。\n",
        "(4)将权重沿着梯度的反方向移动一小步。"
      ],
      "metadata": {
        "id": "jo-9WU20KgDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_step(image,label,model):\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(image)\n",
        "    per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(label,prediction)\n",
        "    average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss,model.weights)\n",
        "    update_weights(gradients,model.weights)\n",
        "    return average_loss\n",
        "\n",
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients,weights):\n",
        "  for g,w in zip(gradients,weights):\n",
        "    w.assign_sub(g*learning_rate)\n"
      ],
      "metadata": {
        "id": "VkyU9xKHKhgp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一轮训练就是对训练数据的每个批量都重复上述训练步骤，而完整的训练循环就是重复多轮训练。"
      ],
      "metadata": {
        "id": "KCwU1CE8ZLVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(images,labels,model,epoches=5,batch_size=128):\n",
        "  batch = BatchGenerator(images,labels,batch_size)\n",
        "  for epoch in range(epoches):\n",
        "    for num in range(batch.batch_num):\n",
        "      image_batch,label_batch = batch.next()\n",
        "     # for i in range(batch_size): 我以为模型只能接收一张图像的输入,但没关系，输入数据将会是(128,28*28)的维度，所以模型只需关注input_size=28*28\n",
        "      loss = train_one_step(image_batch,label_batch,model)\n",
        "\n",
        "      if num % 100 == 0:\n",
        "        print(f\"loss at batch {num}:{loss:.2f}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "u-e9ds9NZH-j"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "运行"
      ],
      "metadata": {
        "id": "z3_F1K73cQrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000,28*28))\n",
        "train_images = train_images.astype(\"float32\")/255\n",
        "\n",
        "test_images = test_images.reshape((10000,28*28))\n",
        "test_images = test_images.astype(\"float32\")/255\n",
        "\n",
        "fit(train_images,train_labels,model,epoches=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h88xQAqfbwbj",
        "outputId": "40099bbf-b722-4a31-ac23-595cb35b3548"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at batch 0:0.83\n",
            "loss at batch 100:0.84\n",
            "loss at batch 200:0.82\n",
            "loss at batch 300:0.80\n",
            "loss at batch 400:0.78\n",
            "loss at batch 0:0.84\n",
            "loss at batch 100:0.82\n",
            "loss at batch 200:0.80\n",
            "loss at batch 300:0.78\n",
            "loss at batch 400:0.77\n",
            "loss at batch 0:0.66\n",
            "loss at batch 100:0.64\n",
            "loss at batch 200:0.63\n",
            "loss at batch 300:0.61\n",
            "loss at batch 400:0.60\n",
            "loss at batch 0:0.73\n",
            "loss at batch 100:0.72\n",
            "loss at batch 200:0.71\n",
            "loss at batch 300:0.70\n",
            "loss at batch 400:0.68\n",
            "loss at batch 0:0.57\n",
            "loss at batch 100:0.56\n",
            "loss at batch 200:0.55\n",
            "loss at batch 300:0.54\n",
            "loss at batch 400:0.53\n",
            "loss at batch 0:0.59\n",
            "loss at batch 100:0.58\n",
            "loss at batch 200:0.58\n",
            "loss at batch 300:0.57\n",
            "loss at batch 400:0.56\n",
            "loss at batch 0:0.47\n",
            "loss at batch 100:0.46\n",
            "loss at batch 200:0.45\n",
            "loss at batch 300:0.45\n",
            "loss at batch 400:0.44\n",
            "loss at batch 0:0.56\n",
            "loss at batch 100:0.55\n",
            "loss at batch 200:0.55\n",
            "loss at batch 300:0.54\n",
            "loss at batch 400:0.53\n",
            "loss at batch 0:0.43\n",
            "loss at batch 100:0.43\n",
            "loss at batch 200:0.42\n",
            "loss at batch 300:0.42\n",
            "loss at batch 400:0.41\n",
            "loss at batch 0:0.47\n",
            "loss at batch 100:0.47\n",
            "loss at batch 200:0.46\n",
            "loss at batch 300:0.46\n",
            "loss at batch 400:0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练完成，评估模型"
      ],
      "metadata": {
        "id": "mInf7EB_d6A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = model(test_images)\n",
        "\n",
        "predictions = predictions.numpy()  # 转化为numpy张量\n",
        "\n",
        "predicted_labels = np.argmax(predictions,axis=1)  # 最终输出的是一个(10000,10)的张量 axis=1指的就是查看概率\n",
        "\n",
        "matches = predicted_labels == test_labels\n",
        "print(f'accuracy:{matches.mean():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcTszd66d5L1",
        "outputId": "0297af78-d6f5-4176-b50a-6cc16523d919"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:0.81\n"
          ]
        }
      ]
    }
  ]
}